**Languages: [English](README_en.md)|[ä¸­æ–‡](README.md)**

# ä»»åŠ¡åŸºæœ¬è¦æ±‚ï¼ˆæ¯ä¸€ä¸ªâ­ï¸=10åˆ†ï¼‰ï¼š

1. [Remote LLM æµ‹è¯• â­ï¸â­ï¸]      è‡ªå·±å‡†å¤‡ä¸å°‘äº3ä¸ªä¾‹å­ï¼Œåœ¨è¿œç¨‹å¤§æ¨¡å‹ä¸Šæµ‹è¯•ã€‚
2. [Local LLM æµ‹è¯•æ•ˆæœ  â­ï¸â­ï¸]   è‡ªå·±å‡†å¤‡ä¸å°‘äº3ä¸ªä¾‹å­ï¼ˆä¿æŒåŒä¸Šï¼‰ï¼Œåœ¨æœ¬åœ°å¤§æ¨¡å‹ä¸Šæµ‹è¯•ã€‚
3. [Local LLM éƒ¨ç½²æƒ…å†µ â­ï¸]      æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨æœ¬åœ°éƒ¨ç½²äº†å¤§æ¨¡å‹
4. [Local LLM åº”ç”¨å¼€å‘ â­â­ï¸â­ï¸]    æ˜¯å¦å·²ç»å°†æ‰€é€‰å®šçš„å¤§æ¨¡å‹ã€ä»»åŠ¡å°è£…æˆäº†ä¸€ä¸ªå¯ä»¥ç›´æ¥è°ƒç”¨çš„ä»£ç ï¼ˆå®ç°æ‰¹é‡è¾“å…¥ã€æ‰¹é‡è¾“å‡ºã€é”™è¯¯å¼‚å¸¸ç®¡ç†ç­‰ï¼Œéœ€è¦è‡ªå·±å‡†å¤‡å¤§é‡æµ‹è¯•æ•°æ®ï¼‰
5. [æ–‡æ¡£â­ï¸â­ï¸]                  æœ¬æ¬¡ä½œä¸šæ¯ä¸ªå°ç»„éƒ½å¿…é¡»ä»¥Github/Gitlabé¡¹ç›®çš„æ–¹å¼æäº¤ï¼Œå…¶ä¸­çš„Readme.md ä¸ºæœ¬æ¬¡å®éªŒæŠ¥å‘Šçš„æ–‡æ¡£ã€‚

## æ¨¡å‹éƒ¨ç½²ï¼ˆWSLä¸Šéƒ¨ç½²ChatGLM3-6B-int4ï¼‰

### ä½œä¸šç¯å¢ƒ
ä½¿ç”¨window11ç³»ç»Ÿï¼š

- Ubuntuï¼š20.04
- nvidia cuda driverï¼š552.22
- CUDAï¼š12.4
- dockerï¼šv20.10.10

æ˜¾å¡é©±åŠ¨è¯·é€‚é…æœ¬æœº CUDA ç‰ˆæœ¬ï¼š<br>
[è‹±ä¼Ÿè¾¾æ˜¾å¡é©±åŠ¨å®˜æ–¹](https://www.nvidia.cn/geforce/drivers/)<br>
[AMDæ˜¾å¡é©±åŠ¨å®˜æ–¹](https://www.amd.com/zh-cn/support/download/drivers.html)


### å®‰è£…WSL
åœ¨ç®¡ç†å‘˜æ¨¡å¼ä¸‹æ‰“å¼€ PowerShell æˆ– Windows å‘½ä»¤æç¤ºç¬¦ï¼Œæ–¹æ³•æ˜¯å³é”®å•å‡»å¹¶é€‰æ‹©â€œä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œâ€ï¼Œè¾“å…¥ï¼š
~~~
wsl --install
~~~
ä½¿ç”¨ WSL å®‰è£… Linux å‘è¡Œç‰ˆçš„è¿‡ç¨‹å®Œæˆåé‡å¯è®¡ç®—æœºï¼Œç„¶åä½¿ç”¨â€œå¼€å§‹â€èœå•æ‰“å¼€è¯¥å‘è¡Œç‰ˆï¼ˆé»˜è®¤æƒ…å†µä¸‹ä¸º Ubuntuï¼‰ï¼Œéœ€è¦ä¸ºæ–°å®‰è£…çš„ Linux å‘è¡Œç‰ˆåˆ›å»ºç”¨æˆ·å¸æˆ·å’Œå¯†ç ã€‚<br>
ï¼ˆè¯·æ³¨æ„ï¼Œè¾“å…¥å¯†ç æ—¶ï¼Œå±å¹•ä¸Šä¸ä¼šæ˜¾ç¤ºä»»ä½•å†…å®¹ï¼Œè¿™ç§°ä¸ºç›²äººé”®å…¥ï¼‰<br>
åˆ›å»ºç”¨æˆ·åå’Œå¯†ç åï¼Œè¯¥å¸æˆ·å°†æ˜¯åˆ†å‘ç‰ˆçš„é»˜è®¤ç”¨æˆ·ï¼Œå¹¶å°†åœ¨å¯åŠ¨æ—¶è‡ªåŠ¨ç™»å½•ï¼Œä¸”æ­¤å¸æˆ·å°†è¢«è§†ä¸º Linux ç®¡ç†å‘˜ï¼Œèƒ½å¤Ÿè¿è¡Œ sudo (Super User Do) ç®¡ç†å‘½ä»¤ã€‚

ä½¿ç”¨å‘è¡Œç‰ˆçš„é¦–é€‰åŒ…ç®¡ç†å™¨å®šæœŸæ›´æ–°å’Œå‡çº§åŒ…ï¼š
~~~
sudo apt update && sudo apt upgrade
~~~

###  å®‰è£…VS Code
è®¿é—® VS Code å®˜æ–¹å®‰è£…é¡µ
[VS Codeå®˜æ–¹ä¸‹è½½](https://code.visualstudio.com/download)<br>
æ³¨æ„ï¼šåœ¨ Windows ä¸Šå®‰è£… Visual Studio Code è€Œä¸æ˜¯åœ¨ WSL æ–‡ä»¶ç³»ç»Ÿä¸­ã€‚

åœ¨ VS Code ä¸­å®‰è£…â€œ WSL æ‹“å±•â€ï¼Œå¯ä»¥ç›´æ¥åœ¨ VS Code ä¸­æœå¯»æ’ä»¶è¿›è¡Œå®‰è£…ï¼Œä¹Ÿå¯ä»¥å»åˆ°å®˜æ–¹çš„ Marketplace ä¸­å®‰è£… [Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-wsl)

é€šè¿‡ä½¿ç”¨ VS Code ä¸­çš„å¿«æ·æ–¹å¼ ```CTRL+SHIFT+P``` è°ƒå‡ºå‘½ä»¤é¢æ¿ï¼Œéšåé”®å…¥ WSLï¼Œä½ å°†çœ‹åˆ°å¯ç”¨çš„é€‰é¡¹åˆ—è¡¨ï¼Œä½ å¯ä»¥åœ¨ WSL ä¼šè¯ä¸­æ‰“å¼€æ–‡ä»¶å¤¹

### å®‰è£…anaconda 
ä¸‹è½½anaconda
ä»¥æˆ‘ä»¬å®‰è£…çš„ 2024.02 ç‰ˆæœ¬ä¸ºä¾‹ï¼Œåœ¨ WSL ç»ˆç«¯è¾“å…¥ï¼š
~~~
wget https://repo.anaconda.com/archive/Anaconda3-2024.02-1-Linux-x86_64.sh
~~~
ï¼ˆå¦‚æœè§‰å¾— wget ä¸‹è½½æ…¢çš„è¯ï¼Œå¯ä»¥ç›´æ¥åœ¨ Windows ä¸Šä¸‹è½½ Linux ç‰ˆæœ¬çš„ Installerï¼Œä¹‹å cd åˆ°ä¸‹è½½ç›®å½•ï¼Œå®‰è£…å³å¯
[Anacondaå®˜æ–¹ä¸‹è½½](https://www.anaconda.com/download/success)ï¼‰
<br><br>
å®‰è£…anacondaï¼Œå®‰è£…è¿‡ç¨‹ä¸­ä¸ç”¨æ›´æ”¹é…ç½®ï¼Œä¸€äº›åè®®å¯ä»¥æŒ‰ q è·³è¿‡ï¼ˆåæ­£ä¹Ÿä¸ä¼šæœ‰äººè¯»çš„ï¼‰ï¼Œå¿…è¦çš„æ—¶å€™è¾“å…¥ yes å³å¯ï¼š
~~~
bash Anaconda3-2024.02-1-Linux-x86_64.sh
~~~

æ‰“å¼€ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼Œæ›´æ”¹ç¯å¢ƒå˜é‡ï¼ˆç”¨æˆ·åæ›¿æ¢ä¸ºè‡ªå·±çš„ç”¨æˆ·åï¼‰ï¼Œæ›´æ–°ç¯å¢ƒå˜é‡ï¼š<br>
~~~
vim ~/.bashrc
~~~
~~~
export PATH="/home/ç”¨æˆ·å/anaconda3/bin:$PATH"
~~~
~~~
source ~/.bashrc
~~~

éªŒè¯ä¸€ä¸‹ï¼Œåœ¨ WSL ç»ˆç«¯é”®å…¥ï¼š
~~~
conda --version
~~~

åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼Œä»¥åŠæ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š
~~~
conda create è™šæ‹Ÿç¯å¢ƒåç§°
~~~
~~~
conda activate è™šæ‹Ÿç¯å¢ƒåç§°
~~~
å¦‚æœåœ¨ç”¨æˆ·åç§°å‰é¢å‡ºç°äº†ç›¸åº”çš„ â€œ(è™šæ‹Ÿç¯å¢ƒåç§°)â€ ï¼Œå°±è¯´æ˜å·²ç»æˆåŠŸå®‰è£…å¹¶æ¿€æ´»äº†ï¼ˆåç»­çš„å®‰è£…æ“ä½œéƒ½é»˜è®¤åœ¨è¿™ä¸ªç¯å¢ƒä¸‹æ“ä½œï¼‰ã€‚

### å®‰è£…CUDA
WSL ä¸­å®‰è£…å’Œæœ¬æœºç›¸åº”çš„ CUDA ç‰ˆæœ¬<br>
é¦–å…ˆï¼Œæ‰“å¼€ PowerShell æˆ– Windows å‘½ä»¤æç¤ºç¬¦åï¼Œè¾“å…¥æŸ¥çœ‹æœ¬æœº CUDA ç‰ˆæœ¬ï¼š
~~~
nvidia-smi
~~~
è®¿é—®å®˜æ–¹ä¸‹è½½ç½‘ç«™
[CUDAå®˜æ–¹ä¸‹è½½](https://developer.nvidia.com/cuda-downloads)<br>
ï¼ˆæˆ‘ä»¬è¿™é‡Œä»¥æœ€æ–°ç‰ˆæœ¬12.4ä¸ºä¾‹å­ï¼Œå…¶ä½™ç‰ˆæœ¬è§
[CUDAå†å²ç‰ˆæœ¬ä¸‹è½½](https://developer.nvidia.com/cuda-toolkit-archive?spm=5176.28103460.0.0.297c3da2OamhJ1)
ï¼‰
<br>
ä¾æ¬¡é€‰æ‹©ï¼š
- (Operating System)ï¼šLinux
- (Architecture)ï¼šx86_64
- (Distribution)ï¼šUbuntu
- (Version)ï¼š20.04
- (Installer Type)ï¼šdeb(local)â€

ç„¶åæ ¹æ®ä¸‹é¢æ‰€ç»™å‡ºçš„ Installation Instructionsï¼ˆå¦‚ä¸‹æ–¹æ¼”ç¤ºçš„æ˜¯ 12.4 ç‰ˆæœ¬çš„ Installation Instructions ï¼‰ï¼Œåœ¨ WSL ç»ˆç«¯ä¸­é¡ºåºè¾“å…¥:
~~~
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda-repo-ubuntu2004-12-4-local_12.4.1-550.54.15-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2004-12-4-local_12.4.1-550.54.15-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2004-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-4
sudo cp /var/cuda-repo-ubuntu2004-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/
~~~
æµ‹è¯•ä¸€ä¸‹ï¼Œé€šè¿‡è¾“å…¥ï¼š
~~~
nvidia-smi
~~~
è‹¥å¯ä»¥æ­£å¸¸æ˜¾ç¤º CUDA Version ï¼Œåˆ™è¯´æ˜å®‰è£…æˆåŠŸã€‚

### å®‰è£…Pytorch
è¯·å®‰è£…å¯¹åº” CUDA ç‰ˆæœ¬çš„ PyTorchã€‚<br>
ï¼ˆå¦‚æœ CUDA ç‰ˆæœ¬å¤§äº PyTorch æ”¯æŒçš„æœ€å¤§ç‰ˆæœ¬ï¼Œåˆ™é€‰æ‹©æœ€å¤§ç‰ˆæœ¬ï¼Œæˆ‘ä»¬è¿™é‡Œä»¥ CUDA ç‰ˆæœ¬ä¸º 12.4 ä¸ºä¾‹ï¼Œå…¶ä½™ç‰ˆæœ¬è§
[Pytorchå†å²ç‰ˆæœ¬ä¸‹è½½](https://pytorch.org/get-started/previous-versions/)<br>
~~~
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
~~~
æµ‹è¯•ä¸€ä¸‹ï¼Œåœ¨ WSL æ§åˆ¶å°ä¸­é¡ºåºè¾“å…¥ï¼š
- python
- import torch
- print(torch.__version__)
- print(f"{torch.cuda.is_available() = }")

å¦‚æœæ‰“å°ç»“æœå¦‚ä¸‹ï¼Œåˆ™è¯´æ˜æ­£ç¡®å®‰è£…ï¼š
>2.3.0+cu121<br>
>torch.cuda.is_available() = True

### éƒ¨ç½²chatglm3-6b-int4

ä» [GitHub](https://github.com/THUDM/ChatGLM3) ä¸‹è½½ ChatGLM3-6B æ¨¡å‹ä»“åº“:
~~~
git clone https://github.com/THUDM/ChatGLM3
~~~
åœ¨é¡¹ç›®ç›®å½•ä¸­ï¼Œå®‰è£…æ¨¡å‹æ‰€éœ€çš„ä¾èµ–é¡¹:
~~~
pip install -r requirements.txt
~~~
æ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œç„¶åä» [Modelscope](https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git) ä¸Š clone å¯¹åº”çš„æ¨¡å‹ï¼š
~~~
mkdir THUDM
~~~
~~~
cd THUDM
~~~
~~~
git lfs install
~~~
~~~
git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git
~~~
~~~
cd ChatGLM3
~~~

ä¹Ÿå¯ä»¥ä»å…¶ä»–åœ°æ–¹ clone å¯¹åº”çš„æ¨¡å‹ï¼š<br>
[HuggingFace](https://huggingface.co/THUDM/chatglm-6b-int4)
ï¼ˆéœ€è¦ç§‘å­¦ä¸Šç½‘ï¼‰<br>
[OpenXLab](https://openxlab.org.cn/models/detail/THUDM/chatglm3-6b)<br>
[å§‹æ™ºAI](https://www.wisemodel.cn/models/ZhipuAI/chatglm3-6b)


æµ‹è¯•ä»£ç ï¼Œå°†æ¨¡å‹è·¯å¾„æ›¿æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹è·¯å¾„ï¼Œå¦‚â€œTHUDM/ChatGLM3â€ï¼š
~~~
from transformers import AutoTokenizer, AutoModel
tokenizer = AutoTokenizer.from_pretrained(æ¨¡å‹è·¯å¾„, >trust_remote_code=True)
model = AutoModel.from_pretrained(æ¨¡å‹è·¯å¾„, >trust_remote_code=True).half().cuda()
response, history = model.chat(tokenizer, "ä½ å¥½")
print(response)
~~~

å¦‚æœæ‰“å°ç»“æœå¦‚ä¸‹ï¼Œåˆ™è¯´æ˜æˆåŠŸå°†å…¶å®‰è£…åˆ°æœ¬åœ°
>ä½ å¥½ğŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚


## æ–¹æ¡ˆé€»è¾‘

æˆ‘ä»¬å®Œæˆäº†æ‰€æœ‰ä»»åŠ¡è¦æ±‚ï¼Œå³å®Œæˆäº†å‰åç«¯çš„å¸ƒç½®ï¼Œåˆå®ç°äº†å°è£…æˆäº†ä¸€ä¸ªå¯ä»¥ç›´æ¥è°ƒç”¨çš„ä»£ç ï¼ˆå®ç°æ‰¹é‡è¾“å…¥ã€æ‰¹é‡è¾“å‡ºã€é”™è¯¯å¼‚å¸¸ç®¡ç†ç­‰ï¼Œéœ€è¦è‡ªå·±å‡†å¤‡å¤§é‡æµ‹è¯•æ•°æ®ï¼‰
### argparser é…ç½®å‚æ•°ä½¿ç”¨æ–¹æ³•
æˆ‘ä»¬å°†qwenæ¨¡å‹å’Œglmæ¨¡å‹ä½¿ç”¨httpçš„å½¢å¼è¿›è¡Œäº†å°è£…ï¼Œé¦–å…ˆè¿è¡Œqwen_predict.pyï¼Œç„¶åè®¾ç½®å‚æ•°è¿è¡Œqwen.pyå³å¯ï¼Œå‚æ•°å¯ä»¥é€‰æ‹©qwen/glmå’Œzh/enï¼Œåˆ†åˆ«å¯¹åº”ç€åƒé—®å¤§æ¨¡å‹/chatglm3-6bå’Œä¸­æ–‡prompt/è‹±æ–‡promptã€‚
![image](readme_imgs/image_1.png)

### åŠŸèƒ½å®ç°
æ‰¹é‡è¯»å–è¾“å‡ºæ˜¯é€šè¿‡æ–‡ä»¶å®ç°çš„ï¼Œ
![image](readme_imgs/image_2.png)
æ–­ç‚¹ç»­ä¼ æ˜¯é€šè¿‡è®°å½•ä»£ç è¿è¡Œçš„æœ€åå¥è¯çš„è¡Œæ•°ç„¶åå­˜å…¥last_line.jsonæ–‡ä»¶ä¸­
ï¼Œè¯¥æ–‡ä»¶ä¼šè®°å½•æ¯ä¸ªæ–‡ä»¶å¤„ç†çš„è¡Œæ•°ï¼Œå¦‚æœä¸‹æ¬¡å¯¹ç›¸åŒæ–‡ä»¶è¿›è¡Œå¤„ç†å°±ä¼šåŠ è½½ä¸Šæ¬¡å¤„ç†çš„è¡Œæ•°ã€‚
![image](readme_imgs/image_11.png)
å¦‚æœéœ€è¦å¤„ç†çš„æ–‡ä»¶åœ¨ä¹‹å‰å¤„ç†è¿‡å°±ä¼šåŠ è½½æœ€åä¸€æ¬¡å¤„ç†çš„è¡Œï¼Œå¦åˆ™è¿”å›0
ç„¶åä¸‹æ¬¡åŠ è½½çš„æ—¶å€™ç›´æ¥åŠ è½½æœ€åä¸€æ¬¡è¿è¡Œçš„å¥å­å³å¯ã€‚
![image](readme_imgs/image_3.png)
åœ¨ç¨‹åºä¸­æˆ‘ä»¬ä¼šå°†å¼‚å¸¸æ— æ³•å¤„ç†çš„è¯­å¥å’Œæå–ä¸å‡ºæ¥çš„è¯­å¥å­˜å…¥åˆ°error_data.txtæ–‡ä»¶ä¸­ï¼Œåœ¨å¤„ç†å®Œæ‰€æœ‰å†…å®¹ä¹‹åä¼šå†æ¬¡è¯»å–
error_data.txt(æ³¨æ„ï¼šåç»­å¯ä»¥åœ¨å¼‚å¸¸å¥å­å¤„å­˜å…¥ä¸€ä¸ªå›è½¦ç¬¦å·ç”¨æ¥å ä½ï¼Œè®°å½•å¼‚å¸¸å¥å­è¡Œæ•°å’Œå†…å®¹ï¼Œæœ€åç»Ÿä¸€å¤„ç†ä¹‹åå¦‚æœå¥å­å¯ä»¥è¢«å¤„ç†å°±é‡æ–°å­˜å…¥å¯¹åº”çš„è¡Œä¸­)æ–‡ä»¶ä¸­çš„å†…å®¹è¿›è¡Œè¿›ä¸€æ­¥å¤„ç†ï¼Œå¦‚æœä¾æ—§ä¸è¡Œå°±å°†ä¾æ—§ä¸è¡Œçš„å¥å­å†æ¬¡å­˜å…¥error_data.txtä¸­ã€‚
![image](readme_imgs/image_8.png)
å¼‚å¸¸æ£€æµ‹ä½¿ç”¨try...exceptè¯­å¥å®ç°ã€‚
### ç»“æœå±•ç¤º
æŠ½å–çš„ç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬åœ¨åŸå§‹æ–‡æœ¬ä¸Šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œå¤„ç†ä¹‹åå†™å…¥æ–‡ä»¶
![image](readme_imgs/image_9.png)
ä¸­è‹±æ–‡promptå¦‚ä¸‹å›¾æ‰€ç¤º(åªå±•ç¤ºä¸­æ–‡)
![image](readme_imgs/image_10.png)
æœ€åçš„å‰åç«¯ç•Œé¢æ ·å¼å¦‚ä¸‹ã€‚
![image](readme_imgs/image_4.png)

### ä»»åŠ¡æµ‹è¯•
æœ€åçš„ä»»åŠ¡æµ‹è¯•æˆ‘ä»¬é€‰ç”¨äº†100æ¡è¯—äººçš„ä¿¡æ¯ï¼Œç„¶ååˆ©ç”¨promptæŠ½å–è¯—äººçš„å­—ã€å·ã€ç¥–ç±ã€å‡ºç”Ÿåœ°ã€ç§°å·ã€ä»£è¡¨ä½œçš„ä¿¡æ¯ã€‚ä¸­æ–‡promptå¦‚å›¾æ‰€ç¤º
![ä¸­æ–‡prompt](readme_imgs/image_5.png)

æŠ½å–æœ€åæ ·ä¾‹å¦‚å›¾æ‰€ç¤º
![æŠ½å–çš„ä¸­æ–‡æ ·ä¾‹å›¾](readme_imgs/image_6.png)


## è¿è¡Œé¡¹ç›®

### é¡¹ç›®ç›®å½•ç»“æ„
```
NLP/
â”œâ”€â”€ chatglm_6b_int4_model/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ quantization.py
â”‚   â”œâ”€â”€ configuration_chatglm.py
â”‚   â”œâ”€â”€ ice_text.model
â”‚   â”œâ”€â”€ quantization_kernels_parallel.c
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”œâ”€â”€ modeling_chatglm.py
â”‚   â”œâ”€â”€ quantization_kernels.c
â”‚   â””â”€â”€ tokenization_chatglm.py 
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data.txt
â”‚   â”œâ”€â”€ error_data.txt
â”‚   â””â”€â”€ prompt/
â”‚       â”œâ”€â”€ prompt_en.txt
â”‚       â””â”€â”€ prompt_zh.txt
â”œâ”€â”€ PromptProject/
â”‚   â”œâ”€â”€ PromptProject
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â””â”€â”€ urls.py
â”‚   â”œâ”€â”€ Test/
â”‚   â”‚   â”œâ”€â”€ templates
â”‚   â”‚   â”‚   â””â”€â”€ main.html
â”‚   â”‚   â”œâ”€â”€ apps.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â””â”€â”€ views.py
â”‚   â””â”€â”€ manage.py
â”œâ”€â”€ result/
â”‚   â”œâ”€â”€ glm_result_zh.txt
â”‚   â”œâ”€â”€ glm_result_en.txt
â”‚   â”œâ”€â”€ qwen_result_zh.txt
â”‚   â”œâ”€â”€ qwen_result_en.txt
â”‚   â””â”€â”€ log/
â”‚       â”œâ”€â”€ app.log
â”‚       â””â”€â”€ last_line.json
â”œâ”€â”€ readme_imgs/
â”‚   â”œâ”€â”€ image_1.png
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ image_11.png
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â””â”€â”€ client.py
```

### é¡¹ç›®è¿è¡Œ
ä»…éœ€ä¿®æ”¹ä¸€ä¸‹ ```main.py``` æ–‡ä»¶ä¸­çš„ ```root_path``` å˜é‡ï¼Œå°†å…¶ä¿®æ”¹ä¸ºä½ å½“å‰çš„æ ¹ç›®å½•å³å¯ä½¿ç”¨
ï¼ˆå¦‚æœæ¨¡å‹æ–‡ä»¶ä½ç½®ä¸åŒï¼Œè¿˜é¡»ä¿®æ”¹ä¸€ä¸‹ ```client.py``` ä¸­çš„ ```model_path``` å˜é‡ï¼‰ï¼Œå¦‚ï¼š
>root_path = "/home/bfeoe/NLP/"

>model_path = "chatglm_6b_int4_model"

å…ˆä»é˜¿é‡Œäº‘è·å–ä¸€ä¸ª qwen æ¨¡å‹çš„ API ï¼Œé˜¿é‡Œäº‘å…è´¹èµ é€300ä¸‡ token æ•°
[é˜¿é‡Œäº‘åƒé—®API](https://help.aliyun.com/zh/dashscope/developer-reference/api-details)
ï¼Œ ```client.py``` ä¸­çš„ ```dashscope.api_key``` å˜é‡ã€‚

### å‘½ä»¤è¡Œæ‰§è¡Œ

é¦–å…ˆï¼Œè¿è¡Œ ```client.py``` æ–‡ä»¶:
~~~
python client.py
~~~
ï¼ˆå¦‚æœå‡ºç°ç«¯å£å ç”¨çš„æƒ…å†µï¼Œä»…éœ€åœ¨æœ€åå¤„ä¿®æ”¹ ```port``` å€¼å³å¯ï¼‰

ç„¶åå°±å¯ä»¥å¼€å§‹è¿›è¡Œä»»åŠ¡äº†ï¼š
~~~
python main.py --model ["qwen", "glm"] --language ["zh", "en"] --data_path "æ–‡ä»¶è·¯å¾„"
~~~

### Webç«¯

é¦–å…ˆï¼ŒåŒå‘½ä»¤è¡Œæ‰§è¡Œæ–¹æ³•ä¸€è‡´ï¼Œå…ˆè¿è¡Œ ```client.py``` æ–‡ä»¶ï¼š
~~~
python client.py
~~~

ç„¶åï¼Œè½¬åˆ°PromptProjectç›®å½•ä¹‹ä¸‹ï¼Œå¯åŠ¨æœåŠ¡å™¨ï¼š
~~~
cd PromptProject
~~~
~~~
python manage.py runserver
~~~

### å…¶ä»–ä¿¡æ¯

æ—¥å¿—ä¿¡æ¯å­˜å‚¨äºæ–‡ä»¶ ```result/log/app.log```<br>
ä»£ç çš„ç»“æœç§»æ­¥è‡³æ–‡ä»¶ ```{model}_result_{language}.txt``` æ–‡ä»¶å¤„æŸ¥çœ‹<br>
å¦‚æœæœ‰æŠ¥é”™æ•°æ®ï¼Œåˆ™å•ç‹¬æŠ½å–å‡ºæ¥ï¼Œå­˜äº ```data/error_data.txt``` æ–‡ä»¶ä¸­<br>
